---
title: "Statistical Learning with FIFA"
subtitle: "An Exercise in Machine Learning with Python"
author: "Michael Sieviec"
date: "7/30/2019"
output: 
  html_document:
    toc: true
---

## Overview

Using [data from FIFA](https://www.kaggle.com/thec03u5/fifa-18-demo-player-dataset), we want to see if we can predict a FIFA player's income using simple linear regression based on various skills as assessed by FIFA on a scale of 1-100. We will also investigate classification of income based on the mean wage. In the process, we will explore some model selection techniques.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## A look at the data
```{r}
library(reticulate)
use_python('/anaconda3/bin/python')
```

```{python}
import numpy as np
import pandas as pd
import os
pd.set_option('display.max_columns', 8)
```

The data come in readily separated files by attribute scores (e.g., Strength) and positional scores (i.e., how good they are as a striker), as well as other information like country of origin and which club they belong to. For our purposes, we are only concerned with their wage attributes, and positional scores. There is an `ID` variable by which to merge them easily.

```{python}
player_wage = pd.read_csv('PlayerPersonalData.csv', usecols = ['ID', 'Wage'])
player_attributes = pd.read_csv('PlayerAttributeData.csv', index_col = 0)
player_position = pd.read_csv('PlayerPlayingPositionData.csv', index_col = 0)
full_data = player_wage.merge(player_attributes, how = 'outer', left_on = 'ID', 
                  right_on = 'ID').merge(player_position, how = 'outer', 
                                 left_on = 'ID', right_on = 'ID')
```

We see there is a dtype warning upon importing the data.

```{python}
full_data.head()

full_data.describe()

full_data.shape
```

We notice there are some symbols that have to be removed as well as some missing values that must be dealt with. Additionally, upon inspection we find some scores above the maximum of 100.

## Cleaning the data

Here we perform some simple cleaning tasks in order to further explore the data. First, we remove rows with empty values.

```{python}
full_data.isnull().any(axis = 1).sum() # number of rows with empty values
full_data = full_data.dropna(axis = 0)
```

Second, we extract the numbers from out wage variable. We find they are all in thousands of euros, so there will not need to be any unit conversions.

```{python}
full_data.Wage.str.extract('([A-Za-z])')[0].unique()
full_data['Wage'] = full_data.Wage.str.extract('(\d+)')
```

Next, we drop the `ID` and `Preferred Positions` variables, as neither are scored skills or positions.

```{python}
full_data = full_data.drop(columns = ['ID', 'Preferred Positions'])
```

Now, we extract only the leading numbers from each score as some are proceeded by +/-, possibly indicating a change in score since the last assessment. Then, we preserve only scores no greater than 100 as per the indicated cap.

```{python}
full_data = full_data.apply(lambda x: x.replace('(\+|\-\d+$)', '', regex = True), 
                            axis = 1).apply(lambda x: x.astype(float))
full_data = full_data[(full_data.drop(columns = 'Wage') <= 100).all(axis = 1)]
full_data.head()
```

The data look much better.

### Exploring with a few visuals

As we are intending to find relationships between skills and wage, we can use a few charts to get an idea of how one effects the other. We will plot a few variables to get a rough idea.

```{python}
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_style('darkgrid')
```

```{python images, fig.align = 'center', cache = T}
plot_st = sns.lmplot('ST', 'Wage', data = full_data)
plt.title('Stiker score vs. wage')
plt.tight_layout()
plt.show()

plot_pen = sns.lmplot('Penalties', 'Wage', data = full_data)
plt.title('Penalties score vs. wage')
plt.tight_layout()
plt.show()

plot_ls = sns.lmplot('Long shots', 'Wage', data = full_data)
plt.title('Long shots score vs. wage')
plt.tight_layout()
plt.show()
```

There appears to be a slight positive correlation between each skill and wage, but nothing very convincing.

## Trying linear regression
```{python}
from sklearn.linear_model import LinearRegression

model_linear = LinearRegression()
predictors = full_data.drop(columns = 'Wage')
response = full_data.Wage
model_linear.fit(predictors, response)
model_linear.score(predictors, response)
```

Reinforcing what we saw in our graphs, we find a small R-squared value--less than 32% of the variance in `Wage` is explained by the variance in the skill and positional scores. We could potentially improve this result by eliminating the 3 outliers at the top of the `Wage` range, but likely not enough to be worth it as 3 out of several thousand would have a small impact. As such, linear regression methods won't be very useful. Given the high-dimensionality of the data, we won't pursue polynomial regression methods, either, due to the computational cost associated with them. We could pursue more sophiscated methods like random forest or gradient boosting regression, but they will be saved for another data set.

## Classification based on the mean wage

Instead of trying to predict wage accurately, perhaps we would have an easier time classifying whether or not a player's income falls above or below the mean. We will compare 5 classifiers--k-nearest neighbors, logistic regression, linear discriminant analysis, quadratic discriminant analysis, and random forest--via cross-validation. We will then choose the best performing model to predict on a new test set.

```{python}
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression as LR
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
from sklearn.ensemble import RandomForestClassifier as RF
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.model_selection import train_test_split

np.random.seed(333)
```

We create the new response variable and assemble our training and testing sets from the data using a 70/30 split:

```{python traintestsplit}
response = [0 if x < np.mean(full_data.Wage) else 1 for x in full_data.Wage]
sum(response)/len(response) # percent of players earning above the mean
train_predictors, test_predictors, train_response, test_response = train_test_split(full_data.drop(columns = 'Wage'),response,train_size = 0.7)
```

We see that less than 26% of players make more than the mean wage.

Now, we fit each model, 10-fold cross-validate them on the training data, and compare their performance with a heatmap. The metrics we will use are precision and recall, as the proportion of "positive" cases--wages above the mean--is much smaller than that of "negative" cases.

```{python models, cache = T}
# logit
model_lr = LR(solver = 'liblinear', max_iter = 10000)
cross_val_lr_pred = cross_val_predict(model_lr, train_predictors, train_response, cv = 10)
rep_lr = classification_report(train_response, cross_val_lr_pred, output_dict=True)

# lda
model_lda = LDA()
cross_val_lda_pred = cross_val_predict(model_lda, train_predictors, train_response, cv = 10)
rep_lda = classification_report(train_response, cross_val_lda_pred, output_dict=True)

# qda
model_qda = QDA()
cross_val_qda_pred = cross_val_predict(model_qda, train_predictors, train_response, cv = 10)
rep_qda = classification_report(train_response, cross_val_qda_pred, output_dict=True)

# knn
model_knn = KNN(n_neighbors = 13)
cross_val_knn_pred = cross_val_predict(model_knn, train_predictors, train_response, cv = 10)
rep_knn = classification_report(train_response, cross_val_knn_pred, output_dict=True)

# random forest
model_rf = RF(n_estimators = 500)
cross_val_rf_pred = cross_val_predict(model_rf, train_predictors, train_response, cv = 10)
rep_rf = classification_report(train_response, cross_val_rf_pred, output_dict=True)
```

```{python heatmap, fig.align = 'center', cache = T}
reports = [x['macro avg'] for x in [rep_knn, rep_lr, rep_lda, rep_qda, rep_rf]]
models = ['KNN', 'Logit', 'LDA', 'QDA', 'R. Forest']
reports_df = pd.DataFrame.from_dict(dict(zip(models, reports)), 
                                    orient = 'index').drop(columns = 'support')
sns.heatmap(reports_df, vmin = 0, vmax = 1, 
            annot = True).set_title('Model performance during cross-validation')
```

We see that random forest classification produced the best f1-score, and also performed the best in both precision and recall. This is the model we will select for predicting on our test set. The disparate performance between LDA and QDA suggests that the decision boundary is more linear than quadratic--sensible, as we divided the class at the mean.

### Evaluating our model on the test data

```{python}
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import auc

model_rf = RF(n_estimators = 500)
model_rf.fit(train_predictors, train_response)
probs_rf = model_rf.predict_proba(test_predictors)[:,1]
precision_rf, recall_rf, threshold_rf = precision_recall_curve(test_response, probs_rf)
pr_rf = pd.DataFrame.from_dict({'recall' : recall_rf, 'precision' : precision_rf}, orient = 'columns')
```

```{python auc, fig.align = 'center', cache = T}
import matplotlib.pyplot as plt
auc_rf = auc(recall_rf, precision_rf)
line_rf = sns.lineplot('recall', 'precision', data = pr_rf, 
                       legend = False).set_title('Random forest performance on test set')
plt.text(x = 0.4, y = 0.6, s = str('AUC = %.3f' % auc_rf))
plt.show()
```

We see that our model does alright with an AUC of ~0.817, and is certainly better than guessing. However, there is still plenty of room for improvement.

## Summary

There does appear to be a positive relationship between a players skill and how much they earn, though it doesn't seem to be linear in nature. Even a simple classification of above or below the mean wage using only skills was not absolutely conclusive given a random forest precision-recall AUC of just under 0.82. This suggests that they contribute to FIFA players' compensation but that there are other factors at play. Perhaps the best way to proceed would be to include some of the other features from the data set as necessary, or even pursing different regression or classification models.

## Notes 

A similar and more recent dataset with more complete information can be found [here on kaggle](https://www.kaggle.com/karangadiya/fifa19).

This analysis was generated using OSX 10.14.5, RStudio v1.1.463, Python 3.7.3, and the following libraries and packages:

* knitr v1.22
* matplotlib v3.1.0
* numpy v1.16.4
* pandas v0.24.2
* reticulate v1.12
* seaborn v0.9.0
* scikit-learn v0.21.2